"""
FinetuneChain í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - force_convert í”Œë˜ê·¸ í¬í•¨ ë²„ì „
LoRA íŒŒì¸íŠœë‹ ëª¨ë¸ê³¼ ChatGPT 2ë‹¨ê³„ ë³€í™˜ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

ì‹¤í–‰ ë°©ë²•:
python test_finetune_chain.py
"""

import sys
import asyncio
import logging
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from finetune_chain import FinetuneChain

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_should_use_lora():
    """LoRA ì‚¬ìš© ì¡°ê±´ í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë¡œì§)"""
    print("\nLoRA ì‚¬ìš© ì¡°ê±´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        from finetune_chain import FinetuneChain
        chain = FinetuneChain.__new__(FinetuneChain)
        
        test_cases = [
            # ê²©ì‹ë„ 5 ì´ìƒ - ë¬´ì¡°ê±´ True
            ({"baseFormalityLevel": 5}, "personal", True),
            ({"baseFormalityLevel": 5}, "business", True),
            
            # ê²©ì‹ë„ 4 + business/report - True
            ({"baseFormalityLevel": 4}, "business", True),
            ({"baseFormalityLevel": 4}, "report", True),
            ({"baseFormalityLevel": 4}, "personal", False),  # personalì€ ì•ˆë¨
            
            # ê²©ì‹ë„ 3 - business/reportì—¬ë„ False
            ({"baseFormalityLevel": 3}, "business", False),
            ({"baseFormalityLevel": 3}, "report", False),
            ({"baseFormalityLevel": 3}, "personal", False),
            
            # formal_document_mode = True - ë¬´ì¡°ê±´ True
            ({"baseFormalityLevel": 2, "formal_document_mode": True}, "personal", True),
            ({"baseFormalityLevel": 1, "formal_document_mode": True}, "business", True),
            
            # sessionFormalityLevel ìš°ì„  ì ìš©
            ({"sessionFormalityLevel": 5, "baseFormalityLevel": 2}, "business", True),
            ({"sessionFormalityLevel": 3, "baseFormalityLevel": 5}, "business", False),
            
            # ë¹ˆ í”„ë¡œí•„ (ê¸°ë³¸ê°’ 3) - False
            ({}, "business", False),
            ({}, "report", False),
            ({}, "personal", False),
        ]
        
        for profile, context, expected in test_cases:
            result = chain._should_use_lora(profile, context)
            status = "í†µê³¼" if result == expected else "ì‹¤íŒ¨"
            print(f"[{status}] í”„ë¡œí•„: {profile}, ì»¨í…ìŠ¤íŠ¸: {context} -> {result} (ì˜ˆìƒ: {expected})")
            
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

async def test_force_convert():
    """ì‚¬ìš©ì ëª…ì‹œì  ìš”ì²­ í…ŒìŠ¤íŠ¸"""
    print(f"\nì‚¬ìš©ì ëª…ì‹œì  ìš”ì²­ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        finetune_chain = FinetuneChain()
    except Exception as e:
        print(f"[ì˜¤ë¥˜] FinetuneChain ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # ì›ë˜ëŠ” ë³€í™˜ ì¡°ê±´ì— ì•ˆ ë§ëŠ” ì¼€ì´ìŠ¤ë“¤
    force_test_cases = [
        {
            "input": "ì•ˆë…•! ì˜¤ëŠ˜ ë­í•´?",
            "profile": {"baseFormalityLevel": 1},  
            "context": "personal",  
            "description": "ìºì£¼ì–¼ + ê°œì¸ì  ëŒ€í™” (ì›ë˜ëŠ” ë³€í™˜ ì•ˆë¨)"
        },
        {
            "input": "ã…‹ã…‹ã…‹ ì¬ë°Œë„¤ ã…ã… ğŸ˜‚",
            "profile": {"baseFormalityLevel": 2},
            "context": "casual",
            "description": "ì´ëª¨í‹°ì½˜ í¬í•¨ ìºì£¼ì–¼ ë©”ì‹œì§€"
        },
        {
            "input": "ë¹¨ë¦¬ë¹¨ë¦¬ í•´ì£¼ì„¸ìš”!!",
            "profile": {},  
            "context": "personal",
            "description": "ë¹ˆ í”„ë¡œí•„ + ê¸‰í•œ ìš”ì²­"
        }
    ]
    
    for i, test_case in enumerate(force_test_cases, 1):
        print(f"\n[ê°•ì œë³€í™˜ í…ŒìŠ¤íŠ¸ {i}] {test_case['description']}")
        print(f"ì›ë³¸: {test_case['input']}")
        
        # 1. ì¼ë°˜ ë³€í™˜ (force_convert=False) - ì‹¤íŒ¨ ì˜ˆìƒ
        try:
            result_normal = await finetune_chain.convert_to_formal(
                input_text=test_case['input'],
                user_profile=test_case['profile'],
                context=test_case['context'],
                force_convert=False
            )
            
            if result_normal['success']:
                print(f"ì¼ë°˜ ë³€í™˜: [ì„±ê³µ] (ì˜ˆìƒì¹˜ ëª»í•¨)")
                print(f"   ê²°ê³¼: {result_normal['converted_text']}")
            else:
                print(f"ì¼ë°˜ ë³€í™˜: [ì‹¤íŒ¨] {result_normal['error']}")
        except Exception as e:
            print(f"ì¼ë°˜ ë³€í™˜: [ì˜¤ë¥˜] {e}")
        
        # 2. ê°•ì œ ë³€í™˜ (force_convert=True) - ì„±ê³µ ì˜ˆìƒ
        try:
            result_forced = await finetune_chain.convert_to_formal(
                input_text=test_case['input'],
                user_profile=test_case['profile'],
                context=test_case['context'],
                force_convert=True
            )
            
            if result_forced['success']:
                print(f"ê°•ì œ ë³€í™˜: [ì„±ê³µ] ({result_forced['method']})")
                print(f"   ê²°ê³¼: {result_forced['converted_text']}")
                print(f"   ë³€í™˜ ì´ìœ : {result_forced['reason']}")
                print(f"   ê°•ì œ ëª¨ë“œ: {result_forced['forced']}")
            else:
                print(f"ê°•ì œ ë³€í™˜: [ì‹¤íŒ¨] {result_forced['error']}")
        except Exception as e:
            print(f"ê°•ì œ ë³€í™˜: [ì˜¤ë¥˜] {e}")
        
        print("-" * 60)

async def test_convenience_method():
    """í¸ì˜ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""
    print(f"\ní¸ì˜ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        finetune_chain = FinetuneChain()
    except Exception as e:
        print(f"[ì˜¤ë¥˜] FinetuneChain ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    test_input = "ì•¼ ì´ê±° ì–¸ì œ í•˜ëƒ?"
    test_profile = {"baseFormalityLevel": 1}
    
    try:
        # convert_by_user_request ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
        result = await finetune_chain.convert_by_user_request(
            input_text=test_input,
            user_profile=test_profile,
            context="personal"
        )
        
        if result['success']:
            print(f"[ì„±ê³µ] í¸ì˜ ë©”ì„œë“œ")
            print(f"ì›ë³¸: {test_input}")
            print(f"ë³€í™˜: {result['converted_text']}")
            print(f"ê°•ì œ ë³€í™˜: {result['forced']}")
            print(f"ë³€í™˜ ì´ìœ : {result['reason']}")
            print(f"ì‚¬ìš© ë°©ë²•: {result['method']}")
        else:
            print(f"[ì‹¤íŒ¨] í¸ì˜ ë©”ì„œë“œ: {result['error']}")
    except Exception as e:
        print(f"[ì˜¤ë¥˜] í¸ì˜ ë©”ì„œë“œ: {e}")

async def test_finetune_chain():
    """FinetuneChain í†µí•© í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("FinetuneChain í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # 1. FinetuneChain ì´ˆê¸°í™”
    try:
        print("\nFinetuneChain ì´ˆê¸°í™” ì¤‘...")
        finetune_chain = FinetuneChain()
        print("[ì„±ê³µ] FinetuneChain ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"[ì˜¤ë¥˜] FinetuneChain ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # 2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    print("\nì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
    print("=" * 40)
    status = finetune_chain.get_status()
    
    print(f"LoRA ìƒíƒœ: {status['lora_status']}")
    print(f"Services ì‚¬ìš© ê°€ëŠ¥: {status['services_available']}")
    print(f"ê¸°ë³¸ ëª¨ë¸ ë¡œë“œë¨: {status['base_model_loaded']}")
    print(f"ë””ë°”ì´ìŠ¤: {status['device']}")
    print(f"LoRA ëª¨ë¸ ê²½ë¡œ: {status['lora_model_path']}")
    print(f"ëª¨ë¸ëª…: {status.get('model_name', 'N/A')}")
    
    # 3. í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ì •
    test_user_profiles = {
        "high_formal": {
            "baseFormalityLevel": 5, 
            "baseFriendlinessLevel": 3,
            "baseEmotionLevel": 2,    
            "baseDirectnessLevel": 4,
            "negativePreferences": {
                "avoidFloweryLanguage": "moderate",
                "avoidRepetitiveWords": "strict",
                "emoticonUsage": "strict"
            },
            "formal_document_mode": True
        },
        "medium_formal": {
            "baseFormalityLevel": 4,
            "baseFriendlinessLevel": 3,
            "baseEmotionLevel": 3,
            "baseDirectnessLevel": 3,
            "negativePreferences": {
                "avoidFloweryLanguage": "moderate"
            }
        },
        "low_formal": {
            "baseFormalityLevel": 2,  # ìºì£¼ì–¼ (LoRA ì‚¬ìš© ì•ˆë¨)
            "baseFriendlinessLevel": 4,
            "baseEmotionLevel": 4,
            "baseDirectnessLevel": 3
        }
    }
    
    # 4. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜
    test_cases = [
        {
            "input": "ì•ˆë…•í•˜ì„¸ìš”! íšŒì˜ ì–¸ì œ í•˜ì£ ?",
            "context": "business",
            "description": "ìºì£¼ì–¼í•œ ì—…ë¬´ ë©”ì‹œì§€ -> ê³µì‹ ë¬¸ì„œ",
            "profile": "high_formal",
            "force_convert": False
        },
        {
            "input": "ë‚´ì¼ í”„ë¡œì íŠ¸ ëë‚´ì•¼ í•´ìš” ğŸ˜­ ë„ì™€ì£¼ì„¸ìš”",
            "context": "business", 
            "description": "ê°ì •ì  í‘œí˜„ -> ê³µì‹ì  ìš”ì²­ì„œ",
            "profile": "high_formal",
            "force_convert": False
        },
        {
            "input": "ì´ê±° ì™œ ì•ˆë˜ëŠ”ì§€ ëª¨ë¥´ê² ë„¤... í™•ì¸ ì¢€ í•´ì£¼ì„¸ìš”",
            "context": "report",
            "description": "ë¶ˆë§Œ í‘œí˜„ -> ê³µì‹ ë³´ê³ ì„œ",
            "profile": "medium_formal",
            "force_convert": False
        },
        {
            "input": "ê¸‰í•˜ê²Œ ì²˜ë¦¬í•´ì•¼ í•  ì¼ì´ ìˆì–´ì„œ ì—°ë½ë“œë ¤ìš”",
            "context": "business",
            "description": "ê¸‰ë°•í•œ ìƒí™© -> ì •ì¤‘í•œ ìš”ì²­",
            "profile": "high_formal",
            "force_convert": False
        },
        {
            "input": "ì¢€ ëŠ¦ì„ ê²ƒ ê°™ì•„ìš” ë¯¸ì•ˆí•´ìš”",
            "context": "personal",  # ê°œì¸ì  -> LoRA ì‚¬ìš© ì•ˆë¨
            "description": "ê°œì¸ì  ì‚¬ê³¼ -> ìºì£¼ì–¼ ìœ ì§€",
            "profile": "low_formal",
            "force_convert": False
        },
        # ê°•ì œ ë³€í™˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
        {
            "input": "ã…‹ã…‹ ê·¸ê±° ì–¸ì œ ëë‚˜ìš”? ğŸ˜…",
            "context": "personal",
            "description": "ì´ëª¨í‹°ì½˜ í¬í•¨ -> ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ê³µì‹í™”",
            "profile": "low_formal",
            "force_convert": True
        },
        {
            "input": "ì•„ ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ğŸ˜¤",
            "context": "personal", 
            "description": "ê°ì • í‘œí˜„ -> ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ê³µì‹í™”",
            "profile": "low_formal",
            "force_convert": True
        }
    ]
    
    # 5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print(f"\ní…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰ ({len(test_cases)}ê°œ)")
    print("=" * 60)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n[í…ŒìŠ¤íŠ¸ {i}] {test_case['description']}")
        print(f"ì›ë³¸: {test_case['input']}")
        print(f"ì»¨í…ìŠ¤íŠ¸: {test_case['context']}")
        print(f"í”„ë¡œí•„: {test_case['profile']}")
        print(f"ê°•ì œ ë³€í™˜: {test_case['force_convert']}")
        
        user_profile = test_user_profiles[test_case['profile']]
        
        try:
            # ê³µì‹ ë¬¸ì„œ ë³€í™˜ ì‹¤í–‰
            start_time = datetime.now()
            result = await finetune_chain.convert_to_formal(
                input_text=test_case['input'],
                user_profile=user_profile,
                context=test_case['context'],
                force_convert=test_case['force_convert']
            )
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # ê²°ê³¼ ì¶œë ¥
            if result['success']:
                print(f"[ì„±ê³µ] ë³€í™˜ ì™„ë£Œ ({duration:.2f}ì´ˆ)")
                print(f"ë³€í™˜ ë°©ë²•: {result['method']}")
                print(f"ë³€í™˜ ì´ìœ : {result['reason']}")
                print(f"ìµœì¢… ê²°ê³¼: {result['converted_text']}")
                
                # LoRA 1ì°¨ ë³€í™˜ ê²°ê³¼ë„ í‘œì‹œ
                if result.get('lora_output') and result['lora_output'] != result['converted_text']:
                    print(f"LoRA 1ì°¨ ë³€í™˜: {result['lora_output']}")
                
            else:
                print(f"[ì‹¤íŒ¨] ë³€í™˜ ì‹¤íŒ¨: {result['error']}")
                print(f"ì‚¬ìš©ëœ ë°©ë²•: {result['method']}")
                print(f"ì‹¤íŒ¨ ì´ìœ : {result['reason']}")
                
        except Exception as e:
            print(f"[ì˜¤ë¥˜] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        
        print("-" * 60)
    
    # 6. ì¡°ê±´ë³„ ë³€í™˜ í…ŒìŠ¤íŠ¸
    print(f"\nì¡°ê±´ë³„ ë³€í™˜ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    condition_tests = [
        {
            "name": "ê²©ì‹ë„ 5 + business (ë¬´ì¡°ê±´ True)",
            "profile": {"baseFormalityLevel": 5},
            "context": "business",
            "should_use_lora": True
        },
        {
            "name": "ê²©ì‹ë„ 4 + business (True)", 
            "profile": {"baseFormalityLevel": 4},
            "context": "business",
            "should_use_lora": True
        },
        {
            "name": "ê²©ì‹ë„ 4 + personal (False)",
            "profile": {"baseFormalityLevel": 4},
            "context": "personal", 
            "should_use_lora": False
        },
        {
            "name": "ê²©ì‹ë„ 3 + business (False)",
            "profile": {"baseFormalityLevel": 3},
            "context": "business",
            "should_use_lora": False
        },
        {
            "name": "ë¹ˆ í”„ë¡œí•„ + business (False)",
            "profile": {},
            "context": "business",
            "should_use_lora": False
        },
        {
            "name": "formal_document_mode = True",
            "profile": {"baseFormalityLevel": 2, "formal_document_mode": True},
            "context": "personal",
            "should_use_lora": True
        }
    ]
    
    for test in condition_tests:
        should_use = finetune_chain._should_use_lora(test['profile'], test['context'])
        status = "í†µê³¼" if should_use == test['should_use_lora'] else "ì‹¤íŒ¨"
        print(f"[{status}] {test['name']}: LoRA ì‚¬ìš© {should_use} (ì˜ˆìƒ: {test['should_use_lora']})")
    
    # 7. ì„±ëŠ¥ ë° ë©”ëª¨ë¦¬ ì •ë³´
    print(f"\nì„±ëŠ¥ ì •ë³´")
    print("=" * 40)
    
    if status['device'] == 'cuda':
        try:
            import torch
            print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
            print(f"GPU ë©”ëª¨ë¦¬ ìµœëŒ€: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB")
            print(f"GPU ë””ë°”ì´ìŠ¤: {torch.cuda.get_device_name()}")
        except Exception as e:
            print(f"[ê²½ê³ ] GPU ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    else:
        print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘")
    
    print(f"\nFinetuneChain ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("FinetuneChain ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("=" * 80)
    
    # 1. ì¡°ê±´ í…ŒìŠ¤íŠ¸
    test_should_use_lora()
    
    # 2. ë©”ì¸ í†µí•© í…ŒìŠ¤íŠ¸
    await test_finetune_chain()
    
    # 3. ê°•ì œ ë³€í™˜ í…ŒìŠ¤íŠ¸
    await test_force_convert()
    
    # 4. í¸ì˜ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
    await test_convenience_method()
    
    print("\n" + "=" * 80)
    print("ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)

if __name__ == "__main__":
    asyncio.run(main())